{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "    return Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA Mars News Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 89.0.4389\n",
      "[WDM] - Get LATEST driver version for 89.0.4389\n",
      "[WDM] - Driver [C:\\Users\\Nick\\.wdm\\drivers\\chromedriver\\win32\\89.0.4389.23\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "browser = init_browser()\n",
    "url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n",
    "browser.visit(url)\n",
    "news_html = browser.html\n",
    "soup = BeautifulSoup(news_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# retreive news title & news paragraph text\n",
    "news_div = soup.find_all('div', class_='content_title')\n",
    "for div in news_div[:2]:\n",
    "    try:\n",
    "        news_title = div.find('a').text\n",
    "    except:\n",
    "        pass\n",
    "news_p = soup.find('div', class_='article_teaser_body').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPL Mars Space Images Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up splinter with url for scraping\n",
    "space_img_url = 'https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/index.html'\n",
    "img_url_prefix = 'https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/'\n",
    "browser.visit(space_img_url)\n",
    "space_img_html = browser.html\n",
    "soup = BeautifulSoup(space_img_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find featured image\n",
    "img_result = soup.find('img',class_='headerimage')\n",
    "# attach full url to image & print link\n",
    "feat_image_url = img_url_prefix + img_result['src']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Facts Table Scrape to HTML string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mars Facts Table Scrape to HTML string\n",
    "table_url = 'https://space-facts.com/mars/'\n",
    "mars_table_html = pd.read_html(table_url, attrs={'id':'tablepress-p-mars-no-2'})\n",
    "\n",
    "# Mars table to HTML string\n",
    "mars_df = mars_table_html[0]\n",
    "mars_df = mars_df.rename(columns={0:\"\",1:\"Mars\"})\n",
    "mars_df.reset_index(drop=True, inplace=True)\n",
    "mars_df_html = mars_df.to_html(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_html_split = mars_df_html.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mars_html = [t for t in mars_html_split]\n",
    "mars_html[0]='<table class=table-striped class=\"dataframe\">'\n",
    "glue = \"\\n\"\n",
    "mars_html = glue.join(mars_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(hemisphere_url)\n",
    "time.sleep(2)\n",
    "hem_html = browser.html\n",
    "hem_soup = BeautifulSoup(hem_html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\anaconda3\\envs\\pythonData\\lib\\site-packages\\splinter\\driver\\webdriver\\__init__.py:490: FutureWarning: browser.find_link_by_partial_text is deprecated. Use browser.links.find_by_partial_text instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Nick\\anaconda3\\envs\\pythonData\\lib\\site-packages\\splinter\\driver\\webdriver\\__init__.py:498: FutureWarning: browser.find_link_by_text is deprecated. Use browser.links.find_by_text instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hem_img_urls = []\n",
    "hem_divs = hem_soup.find_all('div',class_='description')\n",
    "for div in hem_divs:\n",
    "    img_title = div.find('a').text\n",
    "    try:\n",
    "        browser.click_link_by_partial_text(img_title)\n",
    "        time.sleep(1)\n",
    "        browser.click_link_by_text('Sample')\n",
    "    except:\n",
    "        print('not found')\n",
    "    # Grab new window url\n",
    "    new_url = browser.windows[1].url\n",
    "    # Close new window\n",
    "    browser.windows[1].close()\n",
    "    # Visit new url\n",
    "    browser.visit(new_url)\n",
    "    # Grab html and image src url\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    img_tag = soup.find('img')\n",
    "    full_img = img_tag['src']\n",
    "    # save url to list\n",
    "    split = img_title.split(\" \", -1)\n",
    "    del split[-1]\n",
    "    img_title = (\" \").join(split)\n",
    "    hem_dict = {\n",
    "        'title': img_title,\n",
    "        'img_url': full_img\n",
    "    }\n",
    "    hem_img_urls.append(hem_dict)\n",
    "    # Go back to page with mars image list\n",
    "    browser.back()\n",
    "    browser.back()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonEnv",
   "language": "python",
   "name": "pythonenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
